{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# for data visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "# checking the shapes of the train and test datasets\n",
    "print(\"Shape of train: \", train.shape)\n",
    "print(\"Shape of test: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a39bab6a39bdc2812de3b73756ab6f67d9cb154"
   },
   "outputs": [],
   "source": [
    "# making copies of train and test\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8454028c82eb701c9de4ff1a1ef0cfc273064e8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6010a05672d2cac4f66b98cc6b3bf5f998f4e5e4"
   },
   "outputs": [],
   "source": [
    "#Deleting outliers\n",
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
    "\n",
    "#Check the graphic again\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(train['GrLivArea'], train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55ee323f75305ee0a821f9955b8756d0cb498843"
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "sns.distplot(train['SalePrice'] , fit = norm)\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['SalePrice'])\n",
    "print('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot = plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd0d6bb320dbbd26b97285c6a9edf0a447baee5e"
   },
   "outputs": [],
   "source": [
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "#Check the new distribution \n",
    "sns.distplot(train['SalePrice'] , fit = norm)\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['SalePrice'])\n",
    "print('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot = plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51b6e4808fd1a1b7b611aa5ebe68e4c9cb51be73"
   },
   "outputs": [],
   "source": [
    "# combining the train and test datasets for preprocessing\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "# creating y-train\n",
    "y_train = train.SalePrice.values\n",
    "\n",
    "combine = pd.concat([train, test])\n",
    "combine.drop(['SalePrice'], axis = 1, inplace =  True)\n",
    "\n",
    "# printing the shape of new dataset\n",
    "combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8493659ded20717719719b9a60f98d4eb0dec33"
   },
   "outputs": [],
   "source": [
    "combine_na = (combine.isnull().sum() / len(combine)) * 100\n",
    "combine_na = combine_na.drop(combine_na[combine_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :combine_na})\n",
    "missing_data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "969a25f8623999960324f50e1482ee690c45ea21",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking is there are any NULL values in the train and test sets\n",
    "\n",
    "combine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "774b666a3d4f75d5d19c49a68cf7142188384f6c"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtFinSF2\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['BsmtFinSF2'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtFinSF2'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efcd0ec2290cf2026652dd03d82bb1b89b0ef99a"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtFinSF1\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['BsmtFinSF1'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtFinSF1'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "302362621f695a691cb417ef475cc932ed3c79c8"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtFinType2\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['BsmtFinType2'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtFinType2'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe7d450134aac27a56d38c38c1b56686f32e07f3"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtFinType1\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['BsmtFinType1'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtFinType1'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26b8c611a80b874fa2358237bc28ed1833a735ae"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtFullBath\n",
    "\n",
    "# simply filling the NULL value with 0 as it is the most common\n",
    "combine['BsmtFullBath'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtFullBath'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5e28bf496113fcd3a88b8af314cf53b82620b0c"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtHalfBath\n",
    "\n",
    "# simply filling the NULL value with 0 as it is the most common\n",
    "combine['BsmtHalfBath'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtHalfBath'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4b50e800bbe9ecf3155ef4c48efbc20a2b82bb3"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtQual\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['BsmtQual'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtQual'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a2ef6bfeda67fcc204b369a41e8837591fb3ee6"
   },
   "outputs": [],
   "source": [
    "# ## filling the missing values in the Column Types of BsmtUnfSF\n",
    "\n",
    "# simply filling the NULL value with 0 as it is the most common\n",
    "combine['BsmtUnfSF'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['BsmtUnfSF'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "963f1001893a8c153d7ad1c9a6fb8d0eda62cb2b"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of Electrical\n",
    "\n",
    "# simply filling the NULL value with VinylSd as it is the most common\n",
    "combine['Electrical'].fillna(combine['Electrical'].mode()[0], inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['Electrical'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2201a82a45fd7177c71a65081dc30f8623be75df"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of Exterior2nd\n",
    "\n",
    "# simply filling the NULL value with VinylSd as it is the most common\n",
    "combine['Exterior1st'].fillna(combine['Exterior1st'].mode()[0], inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['Exterior1st'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8ddd6d8e66fd4b0b06fd0a2e495be66e11cc68c"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of Exterior2nd\n",
    "\n",
    "# simply filling the NULL value with most common value\n",
    "combine['Exterior2nd'].fillna(combine['Exterior2nd'].mode()[0], inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['Exterior2nd'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37b3aff72cc0567f21e0884e0c9be88d7b4c53e0"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of Fence\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['Fence'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['Fence'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2fa3a5db479e63eb7d27006dde94ac774b9f404"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of FireplaceQu\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['FireplaceQu'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['FireplaceQu'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8491a0a37752581f37bd1eda0d019616ddb49f0e"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of MSZoning\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['MSZoning'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['MSZoning'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee4a5206c88618a089f10c69457532f7fc4d8154"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of MasVnrArea\n",
    "\n",
    "# simply filling the NULL value with 0\n",
    "combine['MasVnrArea'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['MasVnrArea'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4adcf48b40e59a2726fcfc0e2e530496c7bf8c13"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of MasVnrType\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['MasVnrType'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['MasVnrType'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51d8c71f0c0252d53dad6cf3775e17ca1dc0d8a5"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Types of MiscFeature\n",
    "\n",
    "# simply filling the NULL value with none\n",
    "combine['MiscFeature'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['MiscFeature'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a34f34a9973b042a285dee7ec50b6c1af386bdd"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column Typesof PoolQC\n",
    "\n",
    "# simply filling the NULL value with Ex as it is the most common\n",
    "combine['PoolQC'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['PoolQC'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efc099627e5f2b3d08eed0c28e250f7c745552e8"
   },
   "outputs": [],
   "source": [
    "## filling the missing values in the Column SaleType\n",
    "\n",
    "# simply filling the NULL value with WD as it is the most common\n",
    "combine['SaleType'].fillna(combine['SaleType'].mode()[0], inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['SaleType'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "806e477fdacf3852f24640ca1edd5d5d80a27ac7"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the Column TotalBsmtSF\n",
    "\n",
    "combine['TotalBsmtSF'].fillna(combine['TotalBsmtSF'].mean(), inplace = True)\n",
    "\n",
    "# checking if there are any Null values left\n",
    "combine['TotalBsmtSF'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "993b0f84f66d3a3a6ece861c989b5d60d5968db2"
   },
   "outputs": [],
   "source": [
    "# checking the unique value in the column Utlities\n",
    "\n",
    "combine['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be92515aeb178cb7585c9e1b6becf0a269ceb5d4"
   },
   "outputs": [],
   "source": [
    "# AS, we just saw that almost all the rows have same value for Utilities we will get rid of this column\n",
    "\n",
    "combine.drop(['Utilities'], axis = 1, inplace = True)\n",
    "\n",
    "# checking the new shape of the dataset\n",
    "combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a471c3a28dbcfb38b01c94b985de5b019bc1bcbd"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the LotFrontage column\n",
    "\n",
    "#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "combine[\"LotFrontage\"] = combine.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# checking if there are any NULL values left in the LotFronage Column\n",
    "combine['LotFrontage'].isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8821f83bc309a45b66f970742e7f8a5259ee42f"
   },
   "outputs": [],
   "source": [
    "# filling the missing values \n",
    "\n",
    "# we will replace null values with none\n",
    "combine['Alley'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any NULL values left\n",
    "combine['Alley'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3338de12429c2bd067f6665f2b3a9c7428ee5eef"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the BsmtCond column\n",
    "\n",
    "# we are simply filling none in the place NULL values \n",
    "combine['BsmtCond'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['BsmtCond'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63c6db7eea6b5e42791f4a1916802f747748927f"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the BsmtCond column\n",
    "\n",
    "# replacing No with None\n",
    "combine['BsmtExposure'].replace(('No'), ('None'), inplace = True)\n",
    "\n",
    "# we are simply filling None in the place NULL values \n",
    "combine['BsmtExposure'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['BsmtExposure'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "484f18d813ba48f8888f6f6e5566d1e573d74df9"
   },
   "outputs": [],
   "source": [
    "combine['KitchenQual'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72544ff7dbd292781b3d024d5984628c09820a37"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the KitchenQual column\n",
    "\n",
    "# we are simply filling TA in the place NULL values \n",
    "combine['KitchenQual'].fillna(combine['KitchenQual'].mode()[0], inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['KitchenQual'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31212115e2aec2b62789d1bb805dcace5f022b22"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the GarageYrBlt column\n",
    "\n",
    "# we are simply filling none in place of NULL values\n",
    "combine['GarageYrBlt'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['GarageYrBlt'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c718cf68c3dd4935c2cb2267bf9744392855b55d"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the GarageType column\n",
    "\n",
    "# we are simply filling none in the place NULL values \n",
    "combine['GarageType'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['GarageType'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d73e0b2cc73c52de20c3179ee58586b4c7e37a29"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the GarageQual column\n",
    "\n",
    "# we are simply filling none in the place NULL values \n",
    "combine['GarageQual'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['GarageQual'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d402b8ca0ade5639791b03651eb6c12197cd16b"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the GarageFinish column\n",
    "\n",
    "# we are simply filling none in the place NULL values  \n",
    "combine['GarageFinish'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['GarageFinish'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b480fd9509f0ade0fbf1b54b733e6cbc9ba109b4"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the GarageCond column\n",
    "\n",
    "# we are simply filling Unf in the place NULL values \n",
    "combine['GarageCond'].fillna('None', inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['GarageCond'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6b2bd32f4c395fe243dcf9153a7b96eb90710f9"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the GarageCars column\n",
    "\n",
    "# we are simply filling 0 in the place NULL values \n",
    "combine['GarageCars'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['GarageCars'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f06de47716dc1dedaa6d34ff631bb48da1fd1c5"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the GarageArea column\n",
    "\n",
    "# we are simply filling 0 in the place NULL values \n",
    "combine['GarageArea'].fillna(0, inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['GarageArea'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "113912a2bc3b63debfafaad6c94f7a8406e0d979"
   },
   "outputs": [],
   "source": [
    "# filling the missing values in the Functional column\n",
    "\n",
    "combine['Functional'].fillna(combine['Functional'].mode()[0], inplace = True)\n",
    "\n",
    "# checking if there are any left NULL values\n",
    "combine['Functional'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2090825db08ae2698440785f05fd8181006bbce4"
   },
   "outputs": [],
   "source": [
    "combine.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3445acaa5e214b50ce780e1165bd9ed032ab8430"
   },
   "outputs": [],
   "source": [
    "# Transforming some numerical variables that are really categorical\n",
    "\n",
    "#MSSubClass=The building class\n",
    "combine['MSSubClass'] = combine['MSSubClass'].apply(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "combine['OverallCond'] = combine['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "combine['YrSold'] = combine['YrSold'].astype(str)\n",
    "combine['MoSold'] = combine['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7083fab7957ce167a9f7618251bdcb7aea5413b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lb = LabelEncoder() \n",
    "    lb.fit(list(combine[c].values)) \n",
    "    combine[c] = lb.transform(list(combine[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(combine.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb4398b3b1de9f4dd83105975456fc5ffa5be015"
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "# adding a new column total area as it is big determinant for prices of a home.\n",
    "\n",
    "combine['total_area'] = combine['1stFlrSF'] + combine['2ndFlrSF'] + combine['TotalBsmtSF']\n",
    "\n",
    "# looking at the new shape of the combine dataset\n",
    "combine.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa3b3809e6c97e959c09e43347d090f9a25b3d4e"
   },
   "outputs": [],
   "source": [
    "# finding skewed features\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "numerical_feats = combine.dtypes[combine.dtypes != 'object'].index\n",
    "\n",
    "# checking the skewness in all the numerical features\n",
    "skewed_feats = combine[numerical_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\n",
    "\n",
    "# converting the features into a dataframe\n",
    "skewness = pd.DataFrame({'skew':skewed_feats})\n",
    "\n",
    "# checking the head of skewness dataset\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "914aa4945c486c413f17e523f0f2ad95abdc14b3"
   },
   "outputs": [],
   "source": [
    "# applying box-cox transformations\n",
    "\n",
    "skewness = skewness[abs(skewness > 0.8)]\n",
    "\n",
    "# printing how many features are to be box-cox transformed\n",
    "print(\"There are {} skewed numerical features to box cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "# importing box-cox1p\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# defining skewed features\n",
    "skewed_features = skewness.index\n",
    "\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    combine[feat] += 1\n",
    "    combine[feat] = boxcox1p(combine[feat], lam)\n",
    "  \n",
    "combine[skewed_features] = np.log1p(combine[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3d11209ccffe99cbaf05302519a2282bc8b8bd2"
   },
   "outputs": [],
   "source": [
    "# one hot encoding for all the categorical variables\n",
    "\n",
    "combine = pd.get_dummies(combine)\n",
    "\n",
    "# checking the head of the dataset\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc217d1a8ccfc084062a53c9a412808fb15a8743"
   },
   "outputs": [],
   "source": [
    "# separating the train and test datasets\n",
    "\n",
    "x_train = combine.iloc[:ntrain]\n",
    "x_test = combine.iloc[ntrain:]\n",
    "\n",
    "# checking the shapes of train and test datasets\n",
    "print(\"Shape of train :\", x_train.shape)\n",
    "print(\"Shape of test :\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a1e26838dfdbd743455c436605aef845919be08"
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, x_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d6315cd7b825b3ee9f9a4dc13133b8c301abd99",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LASSO MODEL\n",
    "# WITH PIPELINE  and using robust scalerTO AVOID SENSITIVITY TOWARDS OUTLIERS\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha = 0.0005, random_state = 3))\n",
    "lasso.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a36afc69178c55757debac31f05130aab73ce5a5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da1d29f003fe1d86923e266369c88171b5fb3674",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making an Elastic Net model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "ENet.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6de8d3b8db2081e46190d1902b654784d152132"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# making a gradint boosting model\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f119416b608b5510f75e0de35d131957016075de"
   },
   "outputs": [],
   "source": [
    "# making predictions\n",
    "GBoost.fit(x_train, y_train)\n",
    "predictions = GBoost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6436d584b67063c2330ca55fdf8cb891c3585872"
   },
   "outputs": [],
   "source": [
    "# light gradient boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "model_lgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e3cdceced4916b518682f91b3567054c2bff377"
   },
   "outputs": [],
   "source": [
    "predictions = model_lgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f9c1b69ed7804d5185140b452da44720c69a66f"
   },
   "outputs": [],
   "source": [
    "# KERNEL RIDGE REGRESSION\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7020fe3f39e05e85f29cc04655789f53d655e6b5"
   },
   "outputs": [],
   "source": [
    "# STACKING\n",
    "# Simplest model -> Averaging Base Models\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import clone\n",
    "\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7eb9744781b7812846bcbc2997909d4196d17ad5"
   },
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cfb1e75e751f7dd4ba7c8938ab9b281b87384f6"
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a0210a4805b060438b6a6efc15d6b9a15e71738"
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cee4675433d0cf772fc54dc97fac8e16eb8d35ec"
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d4443a10ebbfec9a7029777ce18e5b0391959b8"
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(x_train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(x_train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(x_test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d43a58980458b25b43d81684dcb0316bff0a21e2"
   },
   "outputs": [],
   "source": [
    "# XG BOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cca2e8a2f402f0526c5d648f22581abba35cbf8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_xgb.fit(x_train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(x_train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(x_test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe32eb242566c65c02dab2ecf89ee30d3631a368"
   },
   "outputs": [],
   "source": [
    "model_lgb.fit(x_train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(x_train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(x_test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eaa5d4c616b9961aed6283fb9579371a77765145"
   },
   "outputs": [],
   "source": [
    "'''RMSE on the entire Train data when averaging'''\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train,stacked_train_pred*0.70 +\n",
    "               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "926add869e3e4316b82e49c2b2dd76a346e09b19"
   },
   "outputs": [],
   "source": [
    "predictions = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66227a1c2f9326a283f04112e7c96e32477a91fb"
   },
   "outputs": [],
   "source": [
    "#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\n",
    "\n",
    "submission = pd.DataFrame({'Id': test_ID,'SalePrice': predictions})\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bd6aafb8e36e1a9e3defa24eceb00f00f21ec19"
   },
   "outputs": [],
   "source": [
    "#Convert DataFrame to a csv file that can be uploaded\n",
    "#This is saved in the same directory as your notebook\n",
    "filename = 'submission.csv'\n",
    "\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c0593ef33d7ef8c0d4d0f8e53c9fd548d4a1b09"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
